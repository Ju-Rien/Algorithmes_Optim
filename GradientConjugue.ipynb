{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devoir 3\n",
    "Kevin Chalifoux (17 110 582)\n",
    "/ Julien Corriveau-Trudel (17 090 489)\n",
    "/ Gabriel Dupuis (17 022 516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra;\n",
    "import Pkg; Pkg.add(\"ForwardDiff\");\n",
    "using ForwardDiff;\n",
    "IJulia.clear_output();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient conjugué pour cas quadratique\n",
    "Algorithme du gradient conjugué appliqué au cas quadratique, où \n",
    "\n",
    "$$f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$$\n",
    "$$x \\mapsto x^tQx + c^tx$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC_quad : Algorithme du gradient conjugué appliqué au cas quadratique x^t*Q\n",
    "#\n",
    "# Entrée: Q: Matrice définie positive de la forme quadratique\n",
    "#         c: Vecteur colonne de la forme quadratique\n",
    "#         x0: Point de départ de l'algorithme\n",
    "# Sortie: Point considéré comme minimum local\n",
    "\n",
    "function GC_quad(Q, c, x0)\n",
    "    \n",
    "    # Rend les vecteurs en ligne ou en colonne, selon le cas\n",
    "    try\n",
    "        size(c)[2]\n",
    "    catch\n",
    "        if(typeof(c) == Array{Float64,1} || typeof(c) == Adjoint(Any) || typeof(c) == Adjoint(Float64,Array{Float64,1}))\n",
    "            c = c'\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if size(x0)[1] == 1\n",
    "        x0 = x0'\n",
    "    end\n",
    "    \n",
    "    # Vérifie les dimensions des arguments\n",
    "    if size(Q)[1] != size(Q)[2]\n",
    "        return ArgumentError(\"Argument Q non carré.\")\n",
    "    elseif size(Q)[1] != size(c)[2]\n",
    "        return ArgumentError(\"Argument c de dimension incompatible avec celles de Q.\")\n",
    "    elseif size(Q)[1] != size(x0)[1]\n",
    "        return ArgumentError(\"Argument x0 de dimension incompatible avec celles de Q.\")\n",
    "    end\n",
    "\n",
    "    dim = size(Q)[1]\n",
    "    \n",
    "    # Initialisation\n",
    "    β = 0.0\n",
    "    d = [0 for i in 1:dim]\n",
    "    xk = x0\n",
    "    gk = (xk'*Q+c)\n",
    "    for k in 1:dim\n",
    "        d = -gk' + β*d\n",
    "        θ = -(gk*d)[1]/(d'*Q*d)[1]\n",
    "        xk = xk + θ*d\n",
    "        gk = (xk'*Q+c)\n",
    "        if norm(gk) < eps()\n",
    "            #print(\"SOLUTION = \",xk, \"\\n\")\n",
    "            print(\"...Fin à itération \",k, \"\\n\")\n",
    "            return xk\n",
    "        end\n",
    "        \n",
    "        β = (gk*Q*d)[1]/(d'*Q*d)[1]\n",
    "    end\n",
    "    print(\"...Fin à itération \",dim, \"\\n\")\n",
    "    #print(\"SOLUTION = \",xk, \"\\n\")\n",
    "    return xk\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pas admissible\n",
    "Cet algorithme sera nécessaire pour la version non-quadratique. On utilisera la mise en oeuvre d'un pas admissible tel que vu à la page 150 des NdC de J.-P. Dussault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Pas_Admissible(x, d, f::Function, τ, ∇f)\n",
    "    θ = 1.0\n",
    "    while f(x+θ*d)- f(x) > θ*τ*(∇f*d)[1]\n",
    "        θ = θ/2\n",
    "    end\n",
    "    return θ\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient conjugué appliqué à des fonctions quelconques (non-quadratique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum type_β FR PR HS HZ\n",
    "# GC : Algorithme du gradient conjugué appliqué au cas quadratique x^t*Q\n",
    "#\n",
    "# Entrée: f (Function): fonction à minimiser\n",
    "#         x0 (Array{Float64,1}): Point de départ de l'algorithme\n",
    "#         τ (Float64 ∈[0,0.5]): paramètre de pas admissible pour le critère d'Armijo\n",
    "#         variante_β (type_β): Variante du calcul de β_k\n",
    "# Sortie: Point considéré comme minimum local de la fonction\n",
    "function GConj(f::Function, x0, τ, variante_β, arrêt = Inf, ϵ::Float64 = sqrt(eps()))\n",
    "    \n",
    "    if size(x0)[1] == 1\n",
    "        if size(x0)[2] != 1\n",
    "            return ArgumentError(\"Argument x0 vecteur ligne. Doit être vecteur colonne.\")\n",
    "        end\n",
    "    end\n",
    "    dim = size(x0)[1]\n",
    "    \n",
    "    β = 0.0\n",
    "    d = [0 for i in 1:dim]\n",
    "    xk = x0\n",
    "    #print(\"xk = \",xk, \"\\n\")\n",
    "    g = x -> ForwardDiff.gradient(f, x);\n",
    "    \n",
    "    gk_prec = g(xk)\n",
    "    i = 0\n",
    "    while norm(g(xk)) >= ϵ && i < arrêt\n",
    "        for k in 1:dim\n",
    "            #print(\"Itération \",k, \"\\n\")\n",
    "            gk = g(xk)\n",
    "            #print(\"Norme gk=\", norm(gk), \"\\n\")\n",
    "            if(k == 1)\n",
    "                d = (-gk)\n",
    "            else\n",
    "                d = (-gk + β*d)\n",
    "            end\n",
    "            if (gk'*d)[1] >= 0\n",
    "                i = i + 1\n",
    "                #print(\"Broke out @\", i, \"\\n\")\n",
    "                break\n",
    "            end\n",
    "\n",
    "            θ = Pas_Admissible(xk, 100*d, f, τ, gk')\n",
    "            #print(\"Pas admissible: \", θ, \"\\n\")\n",
    "            \n",
    "            gk_prec = gk\n",
    "            \n",
    "            xk = xk + 100*θ*d\n",
    "            \n",
    "            gk = g(xk)\n",
    "            # Sortir de la boucle si on a gagné\n",
    "            if norm(gk) < ϵ\n",
    "                print(\"...Fin à itération \",i, \"\\n\")\n",
    "                return xk\n",
    "            end\n",
    "            \n",
    "            if variante_β == FR #Fletcher-Reeves\n",
    "                β = norm(gk)^2/norm(gk_prec)^2\n",
    "            elseif variante_β == PR #Polak-Ribière\n",
    "                #yk = (g(xk) - gk_prec)\n",
    "                β = (norm(gk) - (gk'*gk_prec)[1])/norm(gk_prec)^2\n",
    "            elseif variante_β == HS #Heslenes-Stiefet\n",
    "                yk = (gk - gk_prec)\n",
    "                ykd = (yk'*d)[1]\n",
    "                #print(\"(Déno:\", (yk'*d)[1], \") \")\n",
    "                if ykd == 0.0\n",
    "                    i = i + 1\n",
    "                    #print(\"Broke out @\", i, \", because deno is too small.\\n\")\n",
    "                    break\n",
    "                end\n",
    "                β = (gk'*yk)[1]/(yk'*d)[1]\n",
    "            elseif variante_β == HZ #Hager-Zhang\n",
    "                yk = (gk - gk_prec)\n",
    "                ykd = (yk'*d)[1]\n",
    "                if ykd == 0.0\n",
    "                    i = i + 1\n",
    "                    break\n",
    "                end\n",
    "                β = ((yk'*gk)[1] - 2*(norm(yk)^2/ykd)*(d'*gk)[1])/ykd\n",
    "            end\n",
    "            i = i + 1\n",
    "        end\n",
    "    end\n",
    "    print(\"...Fin à itération \",i, \"\\n\")\n",
    "    return xk\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions quadratiques de différentes dimensions ($f(x) = \\frac{1}{2}x^TQx + bx)$, $x\\in \\mathbb{R}^n$)\n",
    "On souhaite tester la fonction ``GC_quad()`` avec des fonctions quadratiques de dimension différentes. Dans cette optique, on choisit des dimensions extrêmes et moyennes, i.e. $n \\in \\{1, 5, 25, 1000\\}$. Ce choix de dimensions testent:\n",
    "\n",
    "* Est-ce que la fonction gère le cas trivial, où la dimension est 1? Cela revient à la recherche linéaire d'une fonction quadratique. \n",
    "* Est-ce que la fonction donne une réponse plausible lorsque les dimensions sont petites?\n",
    "* Est-ce que la fonction donne une réponse plausible lorsque les dimensions sont grandes?\n",
    "\n",
    "Pour générer ces fonctions quadratiques, on requiert des matrices symétriques définies positives, que nous générons par le processus inverse de la diagonalisation: On prend une matrice diagonale $D$ dont les éléments sont positives, donc que les valeurs propres sont positives, et on multiplie à gauche et à droite de $D$ par $P^{T}$ et $P$, où $P$ est inversible.\n",
    "\n",
    "En effet, une telle matrice $Q = P^TDP$ est tel que $\\forall y \\in \\mathbb{R}^n \\backslash \\{0\\}$, $y^TQy = y^TP^TDPy = (Py)^TQPy > 0$, car $P$ inversible $\\Rightarrow Py \\neq 0$ et car $D$ est diagonale strictement positive. \n",
    "\n",
    "Les vecteurs $c$ seront générés aléatoirement, et n'impacteront pas la convexité des fonctions.\n",
    "\n",
    "Le choix de point de départ est trivial, car on a une fonction quadratique, et donc qu'à partir de tous points de départ, l'algorithme arrivera théoriquement à la solution. Nous choisissons donc les $x_{\\text{départ}}= [x_1 \\ldots x_n]^T$ t.q. $x_i = 1, \\forall i \\in \\{1, \\ldots, n\\}$.\n",
    "\n",
    "Générons les matrices $Q$, les vecteurs $c$ et les points de départs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Diagonal(100*rand(Float64,1000,1000))\n",
    "P = UpperTriangular(rand(Float64,1000,1000)) + Diagonal(100*rand(Float64,1000,1000))\n",
    "D1000 = D\n",
    "Q1000 = P'*D*P\n",
    "\n",
    "D = Diagonal(100*rand(Float64,25,25))\n",
    "P = UpperTriangular(rand(Float64,25,25)) + Diagonal(25*rand(Float64,25,25))\n",
    "D25 = D\n",
    "Q25 = P'*D*P\n",
    "\n",
    "D = Diagonal(100*rand(Float64,5,5))\n",
    "P = UpperTriangular(rand(Float64,5,5)) + Diagonal(5*rand(Float64,5,5))\n",
    "\n",
    "D5 = D\n",
    "Q5 = P'*D*P\n",
    "\n",
    "D = Diagonal(100*rand(Float64,1,1))\n",
    "D1 = D\n",
    "Q1 = D;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = [Q1, Q5, Q25, Q1000];\n",
    "c = [100*rand(Float64,1)',100*rand(Float64,5)',100*rand(Float64,25)',100*rand(Float64,1000)'];\n",
    "x0 = [fill(1.,1), fill(1.,5),fill(1.,25), fill(1.,1000)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nécessaire étant générés, appliquons l'algorithme aux fonctions quadratiques, et vérifions si le point résultant est stationnaire en calculant le gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin à itération 1\n",
      "Fin à itération 5\n",
      "Fin à itération 25\n",
      "Fin à itération 1000\n"
     ]
    }
   ],
   "source": [
    "res = [Array{Float64,}, fill(1.,5)', fill(1.,25)',fill(1.,1000)'];\n",
    "for i in 1:4\n",
    "    res[i] = GC_quad(Q[i], c[i], x0[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient #1: \n",
      "[0.0]\n",
      "Gradient #2: \n",
      "[1.02034e-11 2.55369e-11 1.12507e-10 3.38645e-11 1.67992e-9]\n",
      "Gradient #3: \n",
      "[-0.0752351 -0.838377 0.856837 -1.6104 1.17025 0.154147 -0.583765 0.115174 0.680107 0.549322 -0.00503323 0.0192339 -2.56999 0.372975 1.32614 0.779935 0.323408 0.219634 8.65177 0.395746 -1.85479 0.859198 0.52717 0.0143842 0.00984941]\n",
      "Gradient #4: \n",
      "[-378.144 60.8483 42.705 88.0383 -48.6774 -8.70151 -59.5528 78.0017 87.483 -30.8418 -65.4907 -179.915 -42.6045 -33.8849 311.117 -27.9083 15.2604 1.24293 -68.1109 -233.193 -29.6869 8.68264 -34.2542 102.03 -12.5918 -66.5438 67.6947 -19.8243 51.5197 32.2038 9.86182 -23.3751 9.93078 17.0952 -7.08019 20.1362 -87.7462 24.7051 75.0324 2.3963 54.0869 1.03211 -82.4691 54.875 -12.8662 72.962 -15.0686 -126.747 -102.724 -50.3501 -31.6461 46.4385 15.3326 -2.76824 -24.1678 -54.8928 130.277 -16.7296 -63.5163 114.257 15.4543 43.5601 27.5102 7.67728 6.51708 57.7967 70.8343 4.22987 49.5132 -27.2359 -5.19492 -17.2497 8.50004 24.5266 -28.311 13.7693 -129.535 -62.2478 13.8953 3.7861 28.6309 -32.9773 86.6139 -28.4809 37.345 -19.4876 -19.8747 39.1213 -101.385 -90.2962 66.6828 2.48841 -42.3772 65.0239 -141.558 -112.167 -25.9322 -0.18833 18.6681 35.8935 -4.76089 -9.01245 -45.5564 23.9874 18.2625 -28.6335 -31.8365 1.47761 -41.9265 40.1196 121.503 -8.94019 -50.0393 65.0755 -15.2711 0.710257 5.16582 111.48 -31.3684 51.3163 -109.1 17.6031 -31.0251 -53.8892 -18.7641 -40.3613 73.0933 -30.8033 -44.0929 -7.298 28.1427 111.787 -64.2453 -50.2573 4.41424 -55.1546 66.1711 34.5874 24.4832 104.911 -8.30886 -37.127 101.671 34.8137 12.9725 82.3312 18.9359 -29.8132 62.6403 -58.9415 7.15527 93.0904 48.1699 -194.409 -34.0139 -66.278 -32.634 -103.029 13.3809 44.2381 -75.7246 -2.63544 89.7629 -16.5247 -3.4751 27.6018 34.4461 -38.5587 -16.1476 -12.1172 10.6334 35.7418 -57.989 43.0917 35.9352 -1.19362 46.396 107.61 -3.88248 -54.6996 -61.3468 0.896665 15.3983 -97.4847 -24.2465 79.7086 60.1861 21.6644 2.58714 -29.346 18.3494 65.472 41.5562 -31.5279 -80.4756 67.7465 -75.0135 81.3075 -15.8499 -3.0209 -2.44923 48.9691 -71.0412 61.8886 -50.8434 -7.30598 -60.8507 74.5133 -19.0416 82.129 44.776 47.0842 8.40181 28.0109 59.3525 50.6798 12.7723 1.1179 -4.73041 52.531 49.2355 -63.5439 -17.2983 -39.8744 60.734 94.3142 46.2916 -46.7215 -31.7031 153.235 -26.1428 -45.4915 -18.6713 -83.8221 -27.9495 16.6851 -222.074 17.4351 28.6424 2.7341 6.95755 -63.1746 58.9159 -4.06551 -58.8708 9.85252 93.9984 -77.3331 -14.2117 -105.159 7.39241 104.722 -24.0839 55.6971 -37.9476 57.8839 -35.6023 -31.6613 -29.4401 -50.5249 -15.0254 -126.725 -10.245 90.5547 20.6218 -60.6538 130.777 14.7269 50.6014 -15.6467 5.58658 99.5847 71.0725 18.2362 67.9232 -105.926 108.678 -197.831 25.3632 -56.2622 6.86642 -17.2233 68.5484 -51.8365 425.3 22.615 -52.5986 49.2525 10.0132 -55.2845 -129.291 68.89 73.4935 2.63453 25.0034 93.2742 -126.713 -43.4105 -32.8239 15.5632 -19.5052 -59.818 -28.3079 -28.0327 -431.283 -21.429 -18.1688 10.4224 11.4764 5.19607 -17.4146 45.3698 24.2484 -157.49 -10.9561 -111.752 16.5596 -70.6799 -19.8938 -52.2789 -51.7334 -34.0683 -7.70641 19.3055 25.5145 -49.138 -18.9039 21.6741 -36.7661 29.991 41.1771 52.4892 -2.12943 38.3833 -24.0079 65.7023 61.3615 -99.8341 24.5093 140.505 36.0957 35.255 24.528 5.0587 -48.2243 -18.1766 -25.3666 -13.339 -67.7962 -55.4331 -61.3414 -38.8105 4.12555 -153.792 31.8574 11.1726 21.251 34.0334 -94.0995 27.5751 40.8313 -124.226 29.3409 -19.6027 -38.7917 60.0736 -51.1934 11.3749 13.5545 -71.4759 -46.7215 -41.2727 -72.0204 127.075 -39.0589 -76.3266 12.3514 42.8224 96.9195 -32.0489 3.18549 -20.533 -72.171 -58.845 -10.2179 -21.3983 -43.9318 51.8521 78.0478 -25.8117 -23.5593 -7.66425 85.8202 -23.271 -12.9124 25.9172 45.7883 -81.4126 -22.293 -70.8273 84.6479 74.535 3.73859 61.0256 -18.8274 24.0681 -60.6036 -16.9022 -97.0921 3.97171 -51.8375 -90.3695 50.5243 64.3445 9.27138 30.8078 30.9318 46.9839 35.6879 -28.9759 10.2686 38.5063 31.2732 -102.064 0.176762 -2.9557 -56.6384 47.2599 13.4879 -37.2348 -99.5223 -38.8554 -26.3376 43.0019 51.1455 5.66778 -42.3156 57.7675 99.9049 17.5624 -33.9984 85.3024 11.3279 -116.47 77.1647 -27.1363 -14.0045 -50.4373 -6.27396 49.0548 -60.7272 23.1507 4.95007 13.9617 -30.8014 4.3433 -17.392 181.03 -25.1182 5.75097 -40.8083 -10.5868 -61.8286 59.6859 17.0156 20.1457 5.35487 84.8853 102.361 -36.3286 -66.7863 57.3377 82.7351 -5.03625 -64.6747 -45.9845 6.66053 4.38063 5.17763 3.54008 15.0803 55.9075 77.8185 -38.7107 5.80844 87.9687 11.6281 7.47015 -65.6542 -6.25805 -9.97419 -3.75939 -25.5251 -62.4654 -8.44285 26.312 -98.4805 -18.0725 -9.31274 22.411 91.8675 -113.448 14.0781 68.6456 -68.4107 6.42146 -6.63024 -27.4572 107.628 -62.6693 35.1717 69.8174 -60.4228 8.06267 -21.4501 -70.4537 107.921 7.07548 27.1106 -45.9681 -7.18778 43.1021 36.3663 -2.48159 46.0995 -96.2731 -85.7021 -76.8537 -54.3497 232.459 -32.7334 -52.2413 -51.5361 -278.868 -97.6552 -16.3584 20.5616 -106.88 0.495338 31.2331 45.6465 54.5998 -7.97023 -118.438 -12.7258 45.6903 15.7011 58.1208 -13.2406 -17.4616 -68.4133 -106.27 -5.60385 38.2094 36.6973 -17.6811 -101.382 51.467 -30.5311 5.5645 -87.1489 -25.1356 -28.4263 -37.2989 -68.4729 -32.7586 -41.4316 -52.027 -32.2408 -29.0784 -33.8643 16.8507 32.7679 -149.406 -18.872 -323.086 -103.295 75.4669 -112.35 -302.176 7.91775 -53.9627 -4.81397 -23.2832 -29.2679 41.8036 -14.1745 -84.084 7.45406 -3.42371 -115.128 -15.6857 -44.1298 -12.3437 -45.0779 40.0365 -40.5138 26.4613 -10.7988 -11.4606 92.704 -272.286 -58.1301 32.5052 -28.5523 57.345 -15.2545 -40.5505 44.8607 -36.9227 -6.504 -52.89 -4.9849 56.591 -126.173 -76.4494 -55.3485 -12.1659 -97.0346 -8.08237 -7.9815 -30.4175 -15.8917 -28.7284 26.3586 -40.3924 59.5755 -36.6753 -28.1115 28.6109 -9.49066 -85.6944 43.4676 2.36715 -47.9546 -39.1943 60.0878 36.0073 61.0723 -96.2359 83.8151 41.1926 -50.3674 -9.06624 4.05841 -95.3673 -3.36979 -105.152 -13.7202 -18.9236 65.2019 -57.2313 5.03861 -54.6217 -123.041 -72.0354 -111.875 -27.8746 -36.4344 -10.3826 46.2359 -6.14389 3.25735 20.4057 -64.9794 -57.4773 -26.6635 23.5287 -9.18501 98.7644 -21.6832 110.349 -51.3894 94.0811 -101.487 8.79262 -164.045 -14.8344 55.5089 21.2136 84.96 18.2471 30.4276 42.5052 5.13671 -9.05035 -20.2289 35.3879 -60.3394 -21.1723 -26.2606 67.2095 -15.5926 -13.3185 70.6473 40.8857 56.1217 54.468 -56.42 1.20152 17.6937 -14.556 8.65626 -44.9479 -20.282 -21.2322 -63.0036 39.2882 -4.50533 -69.4814 -135.976 -89.743 -42.6998 75.1407 50.3618 -41.1384 31.4742 5.75164 -52.0883 25.7751 -42.929 -57.6587 7.85705 91.7553 10.3773 -38.1458 -66.3684 35.6961 -8.78098 117.38 -23.5766 -75.4058 -20.6751 30.6993 9.73187 -39.3696 -1.53036 -18.5235 -51.6211 81.8946 76.5509 -47.5271 -12.0471 17.1297 -13.0119 -2.40106 32.2238 77.9941 24.1185 -116.486 -65.3171 -281.087 -51.5229 -67.9292 -28.3765 -47.9556 52.1174 -24.1402 -6.24078 67.6226 5.41917 -91.8292 -106.823 87.2102 3.59576 47.0868 108.027 88.6224 -53.682 -25.6164 42.2181 -23.2765 -73.3191 -12.5992 -28.3621 -42.3649 -15.1537 -138.383 235.082 -140.368 -114.077 -69.6495 64.6783 88.4902 -21.3282 -10.7682 -43.6045 62.5942 -86.4666 115.844 13.565 22.9434 -68.5983 -25.9929 63.5835 -0.244161 -61.6268 0.506447 -0.871851 47.6849 -21.7112 -18.9057 84.6202 -50.8581 -63.7351 -4.36199 99.753 11.6889 -29.887 32.3512 34.2689 -13.0559 -37.9491 8.42916 -12.8369 22.0018 -61.1972 -138.834 59.1993 24.1538 5.28848 -18.4219 136.015 13.8947 1.87025 11.4869 104.243 88.6543 -16.0789 -120.747 -19.7664 115.888 40.2971 -36.1912 47.9219 -55.5309 0.88807 19.2627 40.6421 -6.2313 41.5924 -40.428 -11.8525 30.6257 58.9847 -69.915 -7.48086 61.1269 -61.0062 -45.8802 -74.0909 -12.4816 38.8089 -13.0669 45.7463 49.3348 -24.613 -6.18452 49.2497 -32.9144 -41.0193 -21.3227 -28.8081 -48.5009 -38.7946 1.39614 52.613 -26.2111 -42.0983 -54.3349 55.1036 -66.3863 56.7829 19.6579 -62.0929 -99.4927 -18.2161 -34.2209 -9.59884 9.55062 30.6655 40.6522 -71.1004 -38.5778 -11.1308 29.5272 -17.1298 -36.8464 -71.5769 -70.2881 -8.16281 -5.59797 27.1017 83.1579 82.9141 110.421 -65.7484 2.53045 -80.3053 -49.9055 -87.1405 2.3726 -43.8549 -87.0643 -7.10445 -22.2219 16.9754 140.628 -52.2441 -72.9629 1.55558 -55.1269 31.7432 15.0956 -118.291 -46.9256 -22.4569 15.486 -71.4598 3.24269 -24.4208 2.00373 55.4795 54.0075 -243.743 -97.521 9.15889 11.8326 -71.497 37.0828 -15.4154 43.6503 -1.67944 -43.5541 18.2034 -114.453 7.60137 -59.367 18.9417 60.8492 -23.0818 -30.0781 -8.46366 67.5402 -136.735 53.4876 -8.64011 75.5143 -17.8817 -41.8837 32.211 36.8915 61.736 -58.1898 29.6972 9.76933 11.1121 45.7369 37.654 -58.2839 47.3298 115.744 -23.6517 -59.8002 35.3052 -135.377 -63.916 -19.2693 -12.2754 39.6814 61.2814 -33.9375 -68.2285 67.8783 -4.04366 -79.1647 5.10627 -32.0415 -68.732 -2.12334 -51.1858 31.5519 -56.7565 -35.3211 -7.29428 4.18507 3.84015 -59.6318 60.2755 -113.857 -14.9247 51.0988 10.5879 -6.55651 -75.7017 23.5195 54.8697 19.2502 73.5534 11.6423]\n"
     ]
    }
   ],
   "source": [
    "grad = [Array{Float64,}, fill(1.,5)', fill(1.,25)', fill(1.,1000)'];\n",
    "for i in 1:4\n",
    "    grad[i] = res[i]'*Q[i]+c[i]\n",
    "end\n",
    "for i in 1:4\n",
    "    print(\"Gradient #\", i , \": \\n\",grad[i], \"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norme du gradient #1: 0.0\n",
      "Norme du gradient en x0 #1: 117.64108088381661\n",
      "Norme du gradient #2: 1.6842502196205524e-9\n",
      "Norme du gradient en x0 #2: 1229.2899594822622\n",
      "Norme du gradient #3: 9.761058056457271\n",
      "Norme du gradient en x0 #3: 148579.72949430838\n",
      "Norme du gradient #4: 2095.4146860375963\n",
      "Norme du gradient en x0 #4: 1.8528500915899563e8\n"
     ]
    }
   ],
   "source": [
    "gradInitial = [Array{Float64,}, fill(1.,5)', fill(1.,25)', fill(1.,1000)'];\n",
    "for i in 1:4\n",
    "    gradInitial[i] = x0[i]'*Q[i]+c[i]\n",
    "end\n",
    "\n",
    "for i in 1:4\n",
    "    print(\"Norme du gradient #\",i,\": \",norm(grad[i]), \"\\n\")\n",
    "    print(\"Norme du gradient en x0 #\",i,\": \",norm(gradInitial[i]), \"\\n\")\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des résultats\n",
    "#### Convergence\n",
    "On remarque que l'algorithme n'a jamais terminé avant l'itération $n$. Ceci n'est pas surprenant, sachant que la norme du gradient de chacun des points obtenues n'est pas nulle ou inférieur à $eps() = 2.220446049250313\\cdot10^{-16} $.\n",
    "\n",
    "#### Vérification des points résultats\n",
    "\n",
    "On peut vérifier la qualité des résultats en calculant le gradient au points résultants. Comme les points doivent être stationnaires, on s'attend à ce que les gradients soient de norme près de 0. On obtient les normes de gradient pour chacun des points résultants:\n",
    "\n",
    "* $n = 1$: 0.0\n",
    "* $n = 5$: 1.6842502196205524e-9\n",
    "* $n = 25$: 9.761058056457271\n",
    "* $n = 1000$: 2095.4146860375963\n",
    "\n",
    "Pour $n = 1$ et $n = 5$, le résultat est très prometteur. On obtient une norme inférieur à $10^{-8}$. Par contre, pour $n = 25$ et $n = 1000$, on obtient comme norme des gradients aux points résultats des valeurs supérieurs à $\\sqrt{n}$! ($\\sqrt{n}$ est une bonne valeur de comparaison, car c'est la norme du vecteur $[1, 1, \\ldots, 1]^T \\in \\mathbb{R}^n$)\n",
    "\n",
    "On peut se demander toutefois si l'algorithme a tout de même été efficace, dans l'aspect de s'approcher d'un point stationnaire. Quel était la norme du gradient au point initial, soit $[1, 1, \\ldots, 1]^T \\in \\mathbb{R}^n$. Voici les valeurs:\n",
    "\n",
    "* $n = 1$: 117.64108088381661\n",
    "* $n = 5$: 1229.2899594822622\n",
    "* $n = 25$: 148579.72949430838\n",
    "* $n = 1000$: 1.8528500915899563e8\n",
    "\n",
    "On voit que l'algorithme a obtenu un point dont le gradient a grandement été réduit, d'un facteur de norme commençant à $10^{-3}$. Par contre, ça ne nous assure pas que le point obtenu est près du point minimal.\n",
    "\n",
    "Voici une première tentative d'explication des grandes valeurs obtenues pour les gradients des points résultants de l'algorithme pour $n = 25$ et $n = 1000$. Ayant travaillé dans des dimensions moyenne/élevés, les calculs sont nombreux, et les erreurs d'approximation apparaissant dans chaque dimension se cumulent lors des opérations matricielles. Si on applique l'algorithme à nouveau et que ces « grandes » valeurs de norme de gradients persistent, cela appuierait cette hypothèse, car on n'évitera pas les erreurs d'approximations. Voyons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin à itération 1\n",
      "Fin à itération 5\n",
      "Fin à itération 25\n",
      "Fin à itération 1000\n",
      "Norme du gradient #1: NaN\n",
      "Norme du gradient #2: 7.944109290391274e-15\n",
      "Norme du gradient #3: 0.01065746436856588\n",
      "Norme du gradient #4: 1218.9117301472472\n"
     ]
    }
   ],
   "source": [
    "resPrise2 = [Array{Float64,}, fill(1.,5)', fill(1.,25)',fill(1.,1000)'];\n",
    "for i in 1:4\n",
    "    resPrise2[i] = GC_quad(Q[i], c[i], res[i])\n",
    "end\n",
    "gradPrise2 = [Array{Float64,}, fill(1.,5)', fill(1.,25)', fill(1.,1000)'];\n",
    "for i in 1:4\n",
    "    gradPrise2[i] = resPrise2[i]'*Q[i]+c[i]\n",
    "end\n",
    "for i in 1:4\n",
    "    print(\"Norme du gradient #\",i,\": \",norm(gradPrise2[i]), \"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que pour $n = 5$ et $n = 25$, l'algorithme a réussi à se rapprocher de plusieurs magnitude de grandeur d'un gradient nul. Pour la dimension $n = 1$, il est normal qu'on obtienne ``NAN``, car le point fourni était déjà un point stationnaire. Pour $n=1000$, toutefois, on n'arrivera pas à se rapprocher de plus d'un facteur de 2 d'un gradient nul. Par contre, il n'y a pas eu d'augmentation de la norme du gradient résultant. Ceci appuie l'hypothèse que les « grandes » valeurs de normes des gradients obtenues en dimension moyen/élevé sont potentiellement dûes à des erreurs d'approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions quadratiques et non quadratiques pour le Gr. Conj. généralisé\n",
    "On souhaite maintenant tester la fonction ``GConj()``, qui est une extension de l'algorithme du gradient conjugué aux cas non-quadratiques. La différence est au niveau du calcul de $\\beta_k$, qui se fait selon 4 méthodes différentes:\n",
    "\n",
    "Soit $g_k = \\nabla f(x_k)$ et $y_k = g_k - g_{k-1}$, \n",
    "\n",
    "* Méthode de Fletcher et Reeves (FR):\n",
    "$$ \\beta_k^{\\text{FR}} = \\frac{g_{k+1}g_{k+1}^T}{g_kg_k^T}$$\n",
    "\n",
    "* Méthode de Polak et Ribière (PR):\n",
    "$$ \\beta_k^{\\text{PR}} = \\frac{g_{k+1}y_{k+1}^T}{g_kg_k^T}$$\n",
    "\n",
    "* Méthode de Hestenes et Stiefel (HS):\n",
    "$$ \\beta_k^{\\text{HS}} = \\frac{g_{k+1}y_{k+1}^T}{y_{k+1}d_k}$$\n",
    "\n",
    "* Méthode de Hager et Zhang (HZ):\n",
    "$$ \\beta_k^{\\text{HZ}} = \\frac{1}{y_{k+1}d_k}\\left(y_{k+1} - 2d_k^T \\frac{||y_{k+1}||^2}{y_{k+1}d_k} \\right)g_{k+1}^T$$\n",
    "\n",
    "Nécessairement, il faudra tester les fonctions avec les différentes variantes du calcul de $\\beta_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions de tests\n",
    "Selon l'énoncé du devoir, on veut tester l'algorithme avec 2 fonctions quadratiques et 2 fonctions non-quadratiques.\n",
    "Il sera repris les fonctions quadratiques de dimension 5 et 25 utilisées précédemment, afin de pouvoir comparer les résultats de convergence. De plus, dans les fonctions non-quadratiques, il serait souhaitable d'avoir une fonction similaire à une fonction quadratique, disons polynomiale. Celle-ci sera basée sur la fonction de dimension 5, à laquelle on ajoutera des termes non-quadratiques, soit de degré 3. La deuxième fonction non-quadratique sera une combinaison de fonctions trigonométriques, quadratique et exponentielle. Les voici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f4 (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fonctions quadratiques\n",
    "f1(x::Vector) = x'*Q[2]*x/2 + c[2]*x # Dimension 5\n",
    "f2(x::Vector) = x'*Q[3]*x/2 + c[3]*x # Dimension 25\n",
    "\n",
    "# Fonctions non-quadratiques\n",
    "f3(x::Vector) = x'*Q[2]*x/2 - c[2]*x + x[1]^4 + x[2]^4 + x[3]^4 + x[4]^4 #Dimension 5\n",
    "f4(x::Vector) = -exp(1 - (x[1]-1.9)^2 - (x[2]-1.7)^2 - (x[3]-2.5)^2) + 0.5*x[1]^2 + 10*cos(x[1]) #Dimention 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes assuré que les formes quadratiques sont définies positives, par leur construction.\n",
    "\n",
    "Pour les fonctions non-quadratiques, on remarque $f_3$ est la forme $f2$ ajouté de $x_1^4 + x_2^4 + x_3^4 + x_4^4$, et dont la composante linéaire $cx$ est négative plutôt que positive. En ajoutant un polynôme d'ordre 4, je suis assuré qu'un minimum existe.\n",
    "\n",
    "La fonction $f_4 = -e^{1-(x_1-1.9)^2 - (x_2-1.7)^2 - (x_3-2.5)^2} + \\frac{x_1^2}{2} + 10\\cos{x_1}$ est une fonction tiré d'un exercice du *Stewart, J. Calcul à plusieurs variables, 2ème édition*, page 229, #34. On voit que la partie exponentielle est convexe, que la partie polynomiale aussi et que la partie trigonométrique n'affectera pas la présence d'un minimum global, car borné, malgré qu'il puisse cassé la convexité en certains points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthodologie\n",
    "Nous procéderons au test des fonctions en partant du point $[1, 1, \\ldots, 1]^T \\in \\mathbb{R}$, le même point de départ utilisé pour tester l'algorithme limité aux fonctions quadratiques.\n",
    "\n",
    "Les critère d'arrêt, soit $\\epsilon$ et la limite d'itérations seront posés à $\\sqrt{\\epsilon_{\\text{machine}}}$ et à 10000. Ainsi, on cherche une bonne précision (un gradient très près de 0) et on empêche l'algorithme de rouler trop longtemps.\n",
    "\n",
    "Ce test sera fait selon les 4 variantes du calcul de $\\beta_k$, appliqués à chacune des fonctions. Les résultats seront analysés et discutés ensuite.\n",
    "\n",
    "Les $\\tau$ seront choisis selon une légère grille pour voir si le choix affecte la convergence, choisis parmies ``grille_τ = [0.05, 0.2, 0.4]`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour τ = 0.05\n",
      ".Fonction 1\n",
      "..Variante FR\n",
      "...Fin à itération 10000\n",
      "..Variante PR\n",
      "...Fin à itération 10003\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      ".Fonction 2\n",
      "..Variante FR\n",
      "...Fin à itération 10000\n",
      "..Variante PR\n",
      "...Fin à itération 10015\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      ".Fonction 3\n",
      "..Variante FR\n",
      "...Fin à itération 10000\n",
      "..Variante PR\n",
      "...Fin à itération 10000\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      ".Fonction 4\n",
      "..Variante FR\n",
      "...Fin à itération 10001\n",
      "..Variante PR\n",
      "...Fin à itération 10002\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      "Pour τ = 0.2\n",
      ".Fonction 1\n",
      "..Variante FR\n",
      "...Fin à itération 10000\n",
      "..Variante PR\n",
      "...Fin à itération 10003\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      ".Fonction 2\n",
      "..Variante FR\n",
      "...Fin à itération 10000\n",
      "..Variante PR\n",
      "...Fin à itération 10000\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      ".Fonction 3\n",
      "..Variante FR\n",
      "...Fin à itération 10000\n",
      "..Variante PR\n",
      "...Fin à itération 10004\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      ".Fonction 4\n",
      "..Variante FR\n",
      "...Fin à itération 10001\n",
      "..Variante PR\n",
      "...Fin à itération 10000\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      "Pour τ = 0.4\n",
      ".Fonction 1\n",
      "..Variante FR\n",
      "...Fin à itération 10000\n",
      "..Variante PR\n",
      "...Fin à itération 10001\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      ".Fonction 2\n",
      "..Variante FR\n",
      "...Fin à itération 10000\n",
      "..Variante PR\n",
      "...Fin à itération 10003\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      ".Fonction 3\n",
      "..Variante FR\n",
      "...Fin à itération 10000\n",
      "..Variante PR\n",
      "...Fin à itération 10002\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n",
      ".Fonction 4\n",
      "..Variante FR\n",
      "...Fin à itération 10002\n",
      "..Variante PR\n",
      "...Fin à itération 10000\n",
      "..Variante HS\n",
      "...Fin à itération 10000\n",
      "..Variante HZ\n",
      "...Fin à itération 10000\n"
     ]
    }
   ],
   "source": [
    "f = [f1, f2, f3, f4]\n",
    "grille_τ = [0.05, 0.2, 0.4]\n",
    "resTest2 = [];\n",
    "gradTest2 = [Array{Float64,}, fill(1.,25)', fill(1.,5)',fill(1.,3)'];\n",
    "x_depart = [fill(1.,5)', fill(1.,25)', fill(0.,5)',fill(1.,3)'];\n",
    "\n",
    "for τ in grille_τ\n",
    "    print(\"Pour τ = \", τ, \"\\n\")\n",
    "    for i in 1:4\n",
    "        print(\".Fonction \", i, \"\\n\")\n",
    "        for β in (FR, PR, HS, HZ)\n",
    "            print(\"..Variante \", β, \"\\n\")\n",
    "            resTest2 = push!(resTest2, GConj(f[i], x_depart[i]', τ, β, 10000))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour τ = 0.05\n",
      ".Fonction 1\n",
      ".. Variante FR\n",
      "   1.0470517282669527e-6\n",
      ".. Variante PR\n",
      "   2.3010960495389834e-6\n",
      ".. Variante HS\n",
      "   2.6986694229629273e-6\n",
      ".. Variante HZ\n",
      "   2.20273111971459e-6\n",
      ".Fonction 2\n",
      ".. Variante FR\n",
      "   1.3573082113262508e-5\n",
      ".. Variante PR\n",
      "   3.563360340161229e-5\n",
      ".. Variante HS\n",
      "   2.3868210193965534e-5\n",
      ".. Variante HZ\n",
      "   9.54280384256263e-6\n",
      ".Fonction 3\n",
      ".. Variante FR\n",
      "   3.294571105767143e-6\n",
      ".. Variante PR\n",
      "   3.7216081185116453e-6\n",
      ".. Variante HS\n",
      "   2.6314419138128664e-6\n",
      ".. Variante HZ\n",
      "   2.1090351075133664e-6\n",
      ".Fonction 4\n",
      ".. Variante FR\n",
      "   4.90987601757039e-8\n",
      ".. Variante PR\n",
      "   1.6818596293433075e-8\n",
      ".. Variante HS\n",
      "   1.982807074085713e-8\n",
      ".. Variante HZ\n",
      "   2.9692985847873388e-8\n",
      "Pour τ = 0.2\n",
      ".Fonction 1\n",
      ".. Variante FR\n",
      "   1.0470517282669527e-6\n",
      ".. Variante PR\n",
      "   2.3010960495389834e-6\n",
      ".. Variante HS\n",
      "   2.6986694229629273e-6\n",
      ".. Variante HZ\n",
      "   2.20273111971459e-6\n",
      ".Fonction 2\n",
      ".. Variante FR\n",
      "   1.3573082113262508e-5\n",
      ".. Variante PR\n",
      "   3.563360340161229e-5\n",
      ".. Variante HS\n",
      "   2.3868210193965534e-5\n",
      ".. Variante HZ\n",
      "   9.54280384256263e-6\n",
      ".Fonction 3\n",
      ".. Variante FR\n",
      "   3.294571105767143e-6\n",
      ".. Variante PR\n",
      "   3.7216081185116453e-6\n",
      ".. Variante HS\n",
      "   2.6314419138128664e-6\n",
      ".. Variante HZ\n",
      "   2.1090351075133664e-6\n",
      ".Fonction 4\n",
      ".. Variante FR\n",
      "   4.90987601757039e-8\n",
      ".. Variante PR\n",
      "   1.6818596293433075e-8\n",
      ".. Variante HS\n",
      "   1.982807074085713e-8\n",
      ".. Variante HZ\n",
      "   2.9692985847873388e-8\n",
      "Pour τ = 0.4\n",
      ".Fonction 1\n",
      ".. Variante FR\n",
      "   1.0470517282669527e-6\n",
      ".. Variante PR\n",
      "   2.3010960495389834e-6\n",
      ".. Variante HS\n",
      "   2.6986694229629273e-6\n",
      ".. Variante HZ\n",
      "   2.20273111971459e-6\n",
      ".Fonction 2\n",
      ".. Variante FR\n",
      "   1.3573082113262508e-5\n",
      ".. Variante PR\n",
      "   3.563360340161229e-5\n",
      ".. Variante HS\n",
      "   2.3868210193965534e-5\n",
      ".. Variante HZ\n",
      "   9.54280384256263e-6\n",
      ".Fonction 3\n",
      ".. Variante FR\n",
      "   3.294571105767143e-6\n",
      ".. Variante PR\n",
      "   3.7216081185116453e-6\n",
      ".. Variante HS\n",
      "   2.6314419138128664e-6\n",
      ".. Variante HZ\n",
      "   2.1090351075133664e-6\n",
      ".Fonction 4\n",
      ".. Variante FR\n",
      "   4.90987601757039e-8\n",
      ".. Variante PR\n",
      "   1.6818596293433075e-8\n",
      ".. Variante HS\n",
      "   1.982807074085713e-8\n",
      ".. Variante HZ\n",
      "   2.9692985847873388e-8\n"
     ]
    }
   ],
   "source": [
    "∇f = []\n",
    "for τ in grille_τ\n",
    "    print(\"Pour τ = \", τ, \"\\n\")\n",
    "    for j in 1:4\n",
    "        print(\".Fonction \", j, \"\\n\")\n",
    "        ∇f = push!(∇f,x -> ForwardDiff.gradient(f[j], x))\n",
    "        for i in 1:4\n",
    "            print(\".. Variante \", [FR, PR, HS, HZ][i], \"\\n\")\n",
    "            print(\"   \",norm(∇f[j](resTest2[4*(j-1)+i])), \"\\n\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des résultats\n",
    "#### Convergence de l'algorithme\n",
    "Dans tous les cas, autant pour les fonctions quadratiques que non-quadratiques, l'algorithme a effectué $\\pm$10000 itérations, soit la limite posée initialement. De plus, dans tous les cas, l'algorithme a renvoyé un point dont le gradient est très près de 0, soit des gradients de norme au plus $10^{-4}$. Je conclus que l'algorithme fonctionne et converge vers un minimum local si celui-ci est localement existant et accessible.\n",
    "\n",
    "#### Choix de $\\tau$\n",
    "On remarque que le choix de $\\tau$ avec un critère d'itération max à 10000 n'affecte ni le temps de convergence, ni la norme du gradient résultant. Il se peut bien sûr que si on pose la limite d'itération plus basse, le choix de $\\tau$ affecte les déplacements fait. Pour la comparaison des résultats, nous prendrons ceux obtenus avec $\\tau = 0.2$\n",
    "\n",
    "#### Choix de variante de calcul de $\\beta_k$\n",
    "Dans tous les cas, les variantes de calcul de $\\beta_k$ résultent en une différence d'une magnitude d'au plus 10 entre les normes de gradients des points obtenus. Prenons par exemple le résultat de l'algorithme sur $f_2$, avec $\\tau= 2$:\n",
    "* Variante FR:\n",
    "   1.3573082113262508e-5\n",
    "* Variante PR:\n",
    "   3.563360340161229e-5\n",
    "* Variante HS:\n",
    "   2.3868210193965534e-5\n",
    "* Variante HZ:\n",
    "   9.54280384256263e-6\n",
    "\n",
    "Dans ce cas-ci, le ratio entre la plus grande et la plus petite norme du gradient au point résultant est d'environ 3.73. De plus, la variante de Hager et Zhang a donné le meilleur résultat. \n",
    "\n",
    "Pour la fonction $f_1$, la méthode de Fletcher-Reeves l'emporte, pour la fonction $f_3$, celle d'Hager et Zhang est plus fructueuse et pour $f_4$, c'est la méthode de Polak et Ribière qui donne la norme au point résultant le plus petit. \n",
    "\n",
    "#### Comparaison GC version quadratique versus GC version étendue\n",
    "Les fonctions $f1$ et $f2$ ont été reprises des test de l'algorithme du Gradient Conjugué appliqué seulement aux fonctions quadratiques. Ainsi, on peut comparer les résultats obtenus par les deux algorithmes. Voyons les résultats:\n",
    "\n",
    "Commençons avec la norme du gradient du point stationnaire trouvé pour la fonction:\n",
    "##### $f_1$\n",
    "* Algo ``GC_quad``: 1.6842502196205524e-9\n",
    "* Algo ``GConj`` avec:\n",
    "    * Variante FR: 1.0470517282669527e-6\n",
    "    * Variante PR: 2.3010960495389834e-6\n",
    "    * Variante HS: 2.6986694229629273e-6\n",
    "    * Variante HZ: 2.20273111971459e-6\n",
    "    \n",
    "##### $f_2$\n",
    "* Algo ``GC_quad``: 9.761058056457271\n",
    "* Algo ``GConj`` avec:\n",
    "    * Variante FR: 1.3573082113262508e-5\n",
    "    * Variante PR: 3.563360340161229e-5\n",
    "    * Variante HS: 2.3868210193965534e-5\n",
    "    * Variante HZ: 9.54280384256263e-6\n",
    "\n",
    "On observe deux phénomènes. Premièrement, l'algorithme ``GC_quad`` a obtenu de meilleurs résulats au niveau de la fonction de dimension 5. Deuxièmement, c'est l'algorithme ``GConj`` qui remporte le titre d'algorithme le plus efficace au niveau de la fonction quadratique de dimension 25.\n",
    "\n",
    "La théorie suggère que dans les deux cas, les résultats sont supposés être exactement les mêmes, puisque les variantes du calcul de $\\beta_k$ par FR, PR, HS et HZ reviennent au même calcul de $\\beta_k$ dans le cas de l'algorithme pour les fonctions quadratiques et puisque l'algorithme est supposé convergé en au plus $n$ itérations, où $n$ est la dimension du domaine de la fonction.\n",
    "\n",
    "Hors, la théorie ne prédit pas les erreurs de calculs de la machine. On a vu à l'analyse des résultats du premier algorithme que l'augmentation de dimension du domaine de la fonction semble causer une augmentation de la norme du gradient de la fonction au point obtenu par l'algorithme, ce que j'ai expliqué par des erreurs d'approximation de la machine. La force de l'algorithme du gradient conjugué étendu, c'est qu'il ne s'arrête pas à $n$ itérations, de base, et continuera de rouler tant qu'il ne converge pas vers une plus petite valeur de norme de gradient, où qu'il frappe la limite d'itération selon le critère d'arrêt. \n",
    "\n",
    "Cette hypothèse n'explique pas pourquoi l'algo ``GConj`` ne donne pas un meilleur résulat pour la fonction $f_1$. J'expliquerais ceci par la façon dont est calculée la dérivée de la fonction. En effet, dans l'algorithme ``GC_quad``, on utilise la dérivée théorique, soit: $ \\nabla f(x) = x^TQ + c $, directement calculée par la matrice $Q$ et le vecteur $c$. Hors, dans l'algorithme ``GConj``, la dérivée est calculée par la ligne \n",
    "\n",
    "``g = x -> ForwardDiff.gradient(f, x)``.\n",
    "Je considère cette fonction comme une boîte noire au niveau de la précision du résultat, et j'expliquerais donc l'écart de précision par le manque de précision plausible de la fonction ``ForwardDiff.gradient``.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
